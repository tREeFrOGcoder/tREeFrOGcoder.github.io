<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web Page Draft</title>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

</head>
<body>
    <div class="container">


        <!-- Super large cover image section -->
        <section class="cover-image">
            <img src="src/cover.png" alt="Cover Image" class="cover-img">
            <!-- <img src="src/1.1/noisy_im_250.png" alt="Cover Image" class="cover-img"> -->
            <div class="title-block">
                <h1>Diffusion Power:</h1>
                <h2>Pure high-dimensional interpolation magic</h2>
            </div>
        </section>

        


        <!-- Sidebar with navigation -->
        <aside class="sidebar">
            <nav>
                <ul>
                    <li><a href="#sectiona">Part A: Playground</a></li>
                    <ul>
                        <li><a href="#section0">Part 0: Set up</a></li>
                        <li><a href="#section1">Part 1: Sampling</a></li>
                        <ul>
                            <li><a href="#section1.1">1.1 Forward</a></li>
                            <li><a href="#section1.2">1.2 Classic</a></li>
                            <li><a href="#section1.3">1.3 One-Step</a></li>
                            <li><a href="#section1.4">1.4 Interactive</a></li>
                            <li><a href="#section1.5">1.5 Diffusion</a></li>
                            <li><a href="#section1.6">1.6 CFG</a></li>
                            <li><a href="#section1.7">1.7 Translation</a></li>
                            <ul>
                                <li><a href="#section1.7.1">1.7.1 SDEdit</a></li>
                                <li><a href="#section1.7.2">1.7.2 Inpaint</a></li>
                                <li><a href="#section1.7.3">1.7.3 Text</a></li>
                            </ul>
                            <li><a href="#section1.8">1.8 Anagram</a></li>
                            <li><a href="#section1.9">1.9 Hybrid</a></li>
                            <li><a href="#section1.9*">1.9* B&W</a></li>
                        </ul>
                    </ul>
            
                    <li><a href="#sectionb">Part B: Forge</a></li>
                    <ul>
                        <li><a href="#sectionb1">Part 1: UNet</a></li>
                        <ul>
                            <li><a href="#sectionb1.1">1.1 UNet</a></li>
                            <li><a href="#sectionb1.2">1.2 Denoiser</a></li>
                            <ul>
                                <li><a href="#sectionb1.2.1">1.2.1 Train</a></li>
                                <li><a href="#sectionb1.2.2">1.2.2 Test</a></li>
                            </ul>
                        </ul>
                        <li><a href="#sectionb2">Part 2: Diffusion</a></li>
                        <ul>
                            <li><a href="#sectionb2.1">2.1 TCUNet</a></li>
                            <li><a href="#sectionb2.2">2.2 Train</a></li>
                            <li><a href="#sectionb2.3">2.3 Sampling</a></li>
                            <li><a href="#sectionb2.4">2.4 CCUNet</a></li>
                            <li><a href="#sectionb2.5">2.5 Sampling</a></li>
                        </ul>
                    </ul>
                </ul>
            </nav>
            
        </aside>

        
        <!-- Main content section -->
        <main class="content">
            
            <!-- Sectiona -->
            <section id="sectiona" class="section">
                <h1>Part A: Diffusion Playground</h1>
                <ul>
                    <li>Here we explore the power of diffusion models mainly by implementing multiple ways of sampling, which is basically inference.</li>
                    <li>The Diffusion Model we use is DeepFloyd IF with text embeddings from TF.</li>
                    <li>Let's get started!</li>
                </ul>
                <p> </p>
                <!-- Section0 -->
                <section id="section0" class="subsection">
                    <h2>Part 0: Setup and initials</h2>
                    <ul>
                        <li>
                          <p><b>Steps:</b></p>
                          <ul>
                            <li>Created a Hugging Face account and logged in.</li>
                            <li>Accepted the license for the DeepFloyd model and generated a Hugging Face Hub token.</li>
                            <li>Downloaded precomputed text embeddings to avoid GPU memory issues.</li>
                            <li>Instantiated the <code>stage_1</code> and <code>stage_2</code> objects for text-to-image generation.</li>
                            <li>Used provided prompts and experimented with different <code>num_inference_steps</code> values.</li>
                          </ul>
                        </li>
                    </ul>

                    <ul>
                        <li>Below are results of taking different <code>num_inference_steps</code> values for the same prompt. </li>
                        <li><code>num_inference_steps</code> on stage 1 won't affect the quality, but affects where the set of generated images will be on the image manifold.</li>
                        <li>On the other hand, <code>num_inference_steps</code> on stage 2 DO affect the quality of the generated images.</li>
                        <li>It's also obvious that the larger the <code>num_inference_steps</code> on stage 2, the more the details. Compare image 1 and 2, image 3 and 4 to get a feeling for this.</li>
                    </ul>
                    

                    <section id="image-array-single">
                        <div class="image-card-single">
                            <img src="df/0/20-20.png" alt="Image 1">
                            <div class="image-single-info">
                                <p><strong>Stage 1: 20, Stage 2: 20</strong></p>
                            </div>
                        </div>
                    </section>

                    <section id="image-array-single">
                        <div class="image-card-single">
                            <img src="df/0/20-100.png" alt="Image 2">
                            <div class="image-single-info">
                                <p><strong>Stage 1: 20, Stage 2: 100</strong></p>
                            </div>
                        </div>
                    </section>

                    <section id="image-array-single">
                        <div class="image-card-single">
                            <img src="df/0/100-20.png" alt="Image 3">
                            <div class="image-single-info">
                                <p><strong>Stage 1: 100, Stage 2: 20</strong></p>
                            </div>
                        </div>
                    </section>

                    <section id="image-array-single">
                        <div class="image-card-single">
                            <img src="df/0/100-100.png" alt="Image 4">
                            <div class="image-single-info">
                                <p><strong>Stage 1: 100, Stage 2: 100</strong></p>
                            </div>
                        </div>
                    </section>

                </section>
                
                <!-- Section1 -->
                <section id="section1" class="subsection">
                    <h2>Part 1: Sampling Loops for inference</h2>
                    <ul>
                        <li>The key part of this section is to generate images given a Diffusion model,</li>
                        <li>Since the model is trained to denoise following a noise shedule</li>
                        <li>It's hallucination nature would result in inperfect reconstruction of the image from pure noise, which is useful for us to generating new images that also lie on the image manifold.</li>
                        <li>The key to make the generation work is to construct good sampling procedures that guide the model to denoise on the right image at the right timestep for the desired result.</li>
                    </ul>

                    <section id="section1.1" class="subsubsection">
                        <h3>1.1: Implementing the Forward Process</h3>
                        <ul>
                            <li>
                              <p><b>Steps:</b></p>
                              <ul>
                                <li>The forward process in diffusion models: noise is added to a clean image to produce progressively noisier versions.</li>
                                <li>The formula for adding more noise: \( q(x_t \mid x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) \mathbf{I}) \).</li>
                                <li>We compute it using: \( x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, \, \epsilon \sim \mathcal{N}(0, 1) \)</li>
                                <li>Downloaded the Berkeley Campanile image and resized it to 64x64 pixels as the test input.</li>
                                <li>Used the <code>alphas_cumprod</code> variable to compute <code>ᾱ_t</code> values at timesteps <code>t = 250, 500, 750</code>.</li>
                                <li>Implemented the <code>forward(im, t)</code> function to simulate the addition of noise at the specified timesteps.</li>
                              </ul>
                            </li>
                        </ul>

                        <section id="image-array-4">
                            <div class="image-card-4">
                                <img src="df/campnile.png" alt="Image 1">
                                <div class="image-4-info">
                                    <p><strong>Original</strong></p>
                                </div>
                            </div>

                            <div class="image-card-4">
                                <img src="df/1.1/noisy_im_250.png" alt="Image 1">
                                <div class="image-4-info">
                                    <p><strong>Noisy Image at t=250</strong></p>
                                </div>
                            </div>

                            <div class="image-card-4">
                                <img src="df/1.1/noisy_im_500.png" alt="Image 1">
                                <div class="image-4-info">
                                    <p><strong>Noisy Image at t=500</strong></p>
                                </div>
                            </div>

                            <div class="image-card-4">
                                <img src="df/1.1/noisy_im_750.png" alt="Image 1">
                                <div class="image-4-info">
                                    <p><strong>Noisy Image at t=750</strong></p>
                                </div>
                            </div>

                        </section>

                    </section>

                    <section id="section1.2" class="subsubsection">
                        <h3>1.2: Classic Denoising</h3>
                        <ul>
                            <li>The most classic way of denoising is: Gaussian Blurring!</li>
                            <li>So that's what we did here. Just apply Gaussian with kernel_size=9.</li>
                            <li>Of course, we can expect the result to be a blurry mess!</li>
                        </ul>

                        <section id="image-array-small">
                            <div class="image-card-small">
                                <img src="df/1.1/noisy_im_250.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>Noisy Image at t=250</strong></p>
                                </div>
                            </div>

                            <div class="image-card-small">
                                <img src="df/1.1/noisy_im_500.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>Noisy Image at t=500</strong></p>
                                </div>
                            </div>

                            <div class="image-card-small">
                                <img src="df/1.1/noisy_im_750.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>Noisy Image at t=750</strong></p>
                                </div>
                            </div>

                            <div class="image-card-small">
                                <img src="df/1.2/g_denoised_im_250.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>Gaussian Denoised Image at t=250</strong></p>
                                </div>
                            </div>

                            <div class="image-card-small">
                                <img src="df/1.2/g_denoised_im_500.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>Gaussian Denoised Image at t=500</strong></p>
                                </div>
                            </div>

                            <div class="image-card-small">
                                <img src="df/1.2/g_denoised_im_750.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>Gaussian Denoised Image at t=750</strong></p>
                                </div>
                            </div>
                        </section>
                        
                    </section>

                    <section id="section1.3" class="subsubsection">
                        <h3>1.3: One-Step Denoising</h3>
                        <ul>
                            <li>Here we use a pre-trained diffusion model to predic the total amount of noise in a noisy image.</li>
                            <li>Then we use the estimated noise to denoise the image in one step.</li>
                            <li>By giving the diffusion model a default text embedding and the timestep of the noisy image, it can predict the noise in the image.</li>
                            <li>We can expect the result to be worse as the t goes larger, since it's going to be super hard to know what's the exact pattern of the noise on that t=750 image.</li>
                            <li>In fact, I think I can barelly see what's in that t=750 image, which means this is a task even humans find hard.</li>
                        </ul>


                        <section id="image-array-small">
                            <div class="image-card-small">
                                <img src="df/1.1/noisy_im_250.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>Noisy Image at t=250</strong></p>
                                </div>
                            </div>

                            <div class="image-card-small">
                                <img src="df/1.1/noisy_im_500.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>Noisy Image at t=500</strong></p>
                                </div>
                            </div>

                            <div class="image-card-small">
                                <img src="df/1.1/noisy_im_750.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>Noisy Image at t=750</strong></p>
                                </div>
                            </div>

                            <div class="image-card-small">
                                <img src="df/1.3/clean_est_at_timestep_250.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>One-Step Denoised Image at t=250</strong></p>
                                </div>
                            </div>
                            
                            <div class="image-card-small">
                                <img src="df/1.3/clean_est_at_timestep_500.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>One-Step Denoised Image at t=500</strong></p>
                                </div>
                            </div>

                            <div class="image-card-small">
                                <img src="df/1.3/clean_est_at_timestep_750.png" alt="Image 1">
                                <div class="image-small-info">
                                    <p><strong>One-Step Denoised Image at t=750</strong></p>
                                </div>
                            </div>
                        </section>
                        <p>I think our model being able to recover this t=750 to this degree is already impressive!</p>

                    </section>

                    <section id="section1.4" class="subsubsection">
                        <h3>1.4: Interative Denoising</h3>
                        <ul>
                            <li>When your LLM fails to do a good reasoning job, how would you change your prompt?</li>
                            <li>Exactly! You would add a line saying "Please do this step by step".</li>
                            <li>Here, following the intuition and observation we had in task 1.3,</li>
                            <li>We can also say that the denoiser would do a better job if the amount of noise you ask it to estimate is fewer!</li>
                            <li>So, what if we only make the noisy image a little bit less noisy at each step? Would the model do a better job?</li>
                            <li>The answer is YES! So here we are~ We will iteratively give our model the less noisy image (predicted by itself!) for the next prediction.</li>
                            <li>Essentially, we are doing an interpolation between our current noisy image to the target clean image.</li>
                            <li>So, it's also reasonable that if we allow the model to take some small, but more twisted paths, adding a flavor of randomness to it, the result would be better.</li>
                            <li>The key formula we use for this strided "interpolation" is:</li>
                            <li>\( x_{t'} = \frac{\sqrt{\bar{\alpha}_{t'} \beta_t}}{1 - \bar{\alpha}_t} x_0 + \frac{\sqrt{\alpha_t (1 - \bar{\alpha}_{t'})}}{1 - \bar{\alpha}_t} x_t + v_\sigma \)</li>
                            <li>We take a stride of 30, denoising from t=990 to t=0, to save some compute.</li>
                        </ul>

                        <section id="image-array-5">
                            <div class="image-card-5">
                                <img src="df/1.4/iterative_denoise_at_timestep_690.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>Noisy Image at t=690</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.4/iterative_denoise_at_timestep_540.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>Noisy Image at t=540</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.4/iterative_denoise_at_timestep_390.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>Noisy Image at t=390</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.4/iterative_denoise_at_timestep_240.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>Noisy Image at t=240</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.4/iterative_denoise_at_timestep_90.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>Noisy Image at t=90</strong></p>
                                </div>
                            </div>
                        </section>

                        <ul>   
                            <li>Here is good comparison between the three approaches we've tried so far.</li>
                            <li>It's clear that the iterative denoising has more details recovered (hallcinated).</li>
                        </ul>
                        
                        <section id="image-array-4">
                            <div class="image-card-4">
                                <img src="df/campnile.png" alt="Image 1">
                                <div class="image-4-info">
                                    <p><strong>Original Image</strong></p>
                                </div>
                            </div>

                            <div class="image-card-4">
                                <img src="df/1.4/iterative_denoise_final.png" alt="Image 1">
                                <div class="image-4-info">
                                    <p><strong>Iteratively Denoised Image</strong></p>
                                </div>
                            </div>

                            <div class="image-card-4">
                                <img src="df/1.4/one_step_denoise_final.png" alt="Image 1">
                                <div class="image-4-info">
                                    <p><strong>One-Step Denoised Image</strong></p>
                                </div>
                            </div>

                            <div class="image-card-4">
                                <img src="df/1.4/gaussian_blur_final.png" alt="Image 1">
                                <div class="image-4-info">
                                    <p><strong>Gaussian Denoised Image</strong></p>
                                </div>
                            </div>

                        </section>

                    </section>

                    <section id="section1.5" class="subsubsection">
                        <h3>1.5: Diffusion Model Sampling</h3>
                        <ul>
                            <li>Remember I repeatitively use the word "hallucination"?</li>
                            <li>That's because whenever the pre-trained diffusion model is given a noisy image,</li>
                            <li>it's basically imagining what patterns of noise are covering that image, which made it like a noisy image at timestep t.</li>
                            <li>Imagining the pattern of noise is the essentially imagining the details back into the image, based on experience, just like you and I!</li>
                            <li>This gives our model the power of imagination, which is very useful when you force it to do a denoise task based on a purely noisy image.</li>
                            <li>That's when the magic happens and the model literally generates a complete new image from nothing!</li>
                            <li>(I mean, we humans can also do this, and we typically do this with our eyes closed, and we call this day-dreaming!)</li>
                            <li>Now, you should get a sense of how romantic this is for a diffusion to be able to do!</li>
                        </ul>

                        <section id="image-array-5">
                            <div class="image-card-5">
                                <img src="df/1.5/generated_image_1.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>Interpolation from "nothingness" 1</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.5/generated_image_2.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>Interpolation from "nothingness" 2</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.5/generated_image_3.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>Interpolation from "nothingness" 3</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.5/generated_image_4.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>Interpolation from "nothingness" 4</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.5/generated_image_5.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>Interpolation from "nothingness" 5</strong></p>
                                </div>
                            </div>
                    </section>

                    <section id="section1.6" class="subsubsection">
                        <h3>1.6: Classifier-Free Guidance (CFG)</h3>
                        <ul>
                            <li>We all see that the result does't look good enough. They are gray-ish, dull and foggy. Not real enough. How to improve?</li>
                            <li>Hemmmm, if only there is a way that we can tell our model: "Hey! Your current generation is not real enough. Make it MORE real."</li>
                            <li>Luckily, where there is a will, there is a way.</li>
                            <li>Recall that for previous part, we always use "a high quality photo" as a "null prompt".</li>
                            <li>Well, I think "" would be even stronger "null prompt" --- it's more "null" then the highly-quality-photo one,</li>
                            <li>So, we can now use something similar to an extrapolation: \( \epsilon = \epsilon_u + \gamma (\epsilon_c - \epsilon_u) \),</li>
                            <li>to add more weight to the "highly-quality-photo" prompt,</li>
                            <li>effectively giving the model more tendency to generate images that have more "high-quality-photo-ness".</li>
                            <li>Here we choose \( \gamma = 7\).</li>
                        </ul>

                        <section id="image-array-5">
                            <div class="image-card-5">
                                <img src="df/1.6/generated_image_with_cfg_1.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>CFG Enhanced 1</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.6/generated_image_with_cfg_2.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>CFG Enhanced 2</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.6/generated_image_with_cfg_3.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>CFG Enhanced 3</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.6/generated_image_with_cfg_4.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>CFG Enhanced 4</strong></p>
                                </div>
                            </div>

                            <div class="image-card-5">
                                <img src="df/1.6/generated_image_with_cfg_5.png" alt="Image 1">
                                <div class="image-5-info">
                                    <p><strong>CFG Enhanced 5</strong></p>
                                </div>
                            </div>
                        </section>


                    </section>

                    <section id="section1.7" class="subsubsection">
                        <h3>1.7: Image-to-Image Translation</h3>
                        <ul>
                            <li>Knonwing the power of injecting "realism" to models with CFG, we can now ask it "denoise + make more real" from given noisy images.</li>
                            <li>This is called Image-to-Image translation (SDEdit to be specific for our technique here). You can imagine that if the noise is too much, or close to pure noise, the generated result should be close to those in 1.6, which are random "real" images.</li>
                            <li>But for noisy images with less noise, the generated result can be pretty "real" and interesting.</li>
                            <li>Here we choose noise levels from [1, 3, 5, 7, 10, 20], which corresponds to timesteps ranging from 960 to 390. The smaller the noise_level, the more the noise. Sorry but this is for implementation's sake.</li>
                            <li>And we can expect generated results to become more reasonable and close to the given original image as noise level goes up (---the amount of noise goes down).</li>
                        </ul>

                        <section id="image-array-7">
                            <div class="image-card-7">
                                <img src="df/1.7/test_image_1.png" alt="Image 1">
                                <div class="image-7-info">
                                    <p><strong>SDEdit with noise_level=1</strong></p>
                                </div>
                            </div>

                            <div class="image-card-7">
                                <img src="df/1.7/test_image_3.png" alt="Image 1">
                                <div class="image-7-info">
                                    <p><strong>SDEdit with noise_level=3</strong></p>
                                </div>
                            </div>

                            <div class="image-card-7">
                                <img src="df/1.7/test_image_5.png" alt="Image 1">
                                <div class="image-7-info">
                                    <p><strong>SDEdit with noise_level=5</strong></p>
                                </div>
                            </div>

                            <div class="image-card-7">
                                <img src="df/1.7/test_image_7.png" alt="Image 1">
                                <div class="image-7-info">
                                    <p><strong>SDEdit with noise_level=7</strong></p>
                                </div>
                            </div>

                            <div class="image-card-7">
                                <img src="df/1.7/test_image_10.png" alt="Image 1">
                                <div class="image-7-info">
                                    <p><strong>SDEdit with noise_level=10</strong></p>
                                </div>
                            </div>

                            <div class="image-card-7">
                                <img src="df/1.7/test_image_20.png" alt="Image 1">
                                <div class="image-7-info">
                                    <p><strong>SDEdit with noise_level=20</strong></p>
                                </div>
                            </div>

                            <div class="image-card-7">
                                <img src="df/campnile.png" alt="Image 1">
                                <div class="image-7-info">
                                    <p><strong>Original Image</strong></p>
                                </div>
                            </div>
                        </section>



                        <section id="section1.7.1" class="subsubsubsection">
                            <h4>1.7.1: SDEdit -- Editing Hand-Drawn and Web Images</h4>
                            <ul>
                                <li>Due to the "real-ness" tendency of generation image, we expect the model to do some magic on hand-drawn images and random web images</li>
                            </ul>


                            <p>This </p>
                            <section id="image-array-7">
                                <div class="image-card-7">
                                    <img src="df/1.7/test_image_1.png" alt="Image 1">
                                    <div class="image-7-info">
                                        <p><strong>SDEdit with noise_level=1</strong></p>
                                    </div>
                                </div>
                            </section>





                        </section>

                        <section id="section1.7.2" class="subsubsubsection">
                            <h4>1.7.2: Inpainting</h4>
                        </section>

                        <section id="section1.7.3" class="subsubsubsection">
                            <h4>1.7.3: Text-Conditional Image-to-Image Translation</h4>


                            <section id="image-array-4">
                                <div class="image-card-4">
                                    <img src="df/1.4/gaussian_blur_final.png" alt="Image 1">
                                    <div class="image-4-info">
                                        <p><strong>gaussian_blur_final</strong></p>
                                    </div>
                                </div>

                                <div class="image-card-4">
                                    <img src="df/1.4/gaussian_blur_final.png" alt="Image 1">
                                    <div class="image-4-info">
                                        <p><strong>gaussian_blur_final</strong></p>
                                    </div>
                                </div>

                                <div class="image-card-4">
                                    <img src="df/1.4/gaussian_blur_final.png" alt="Image 1">
                                    <div class="image-4-info">
                                        <p><strong>gaussian_blur_final</strong></p>
                                    </div>
                                </div>


                                <div class="image-card-4">
                                    <img src="df/1.4/gaussian_blur_final.png" alt="Image 1">
                                    <div class="image-4-info">
                                        <p><strong>gaussian_blur_final</strong></p>
                                    </div>
                                </div>
                            </section>

                        </section>

                    </section>

                    <section id="section1.8" class="subsubsection">
                        <h3>1.8: Visual Anagrams</h3>
                    </section>

                    <section id="section1.9" class="subsubsection">
                        <h3>1.9: Hybrid Images</h3>
                    </section>

                    <section id="section1.9*" class="subsubsection">
                        <h3>1.9*: Bells & Whistles</h3>
                    </section>

                </section>




                

            </section>

            <section id="sectionb" class="section">
                <h1>Part B: Diffusion Forge</h1>

                <section id="sectionb1" class="subsubsection">
                    <h2>Part 1: Training a Single-Step Denoising UNet</h2>

                    <section id="sectionb1.1" class="subsubsubsection">
                        <h3>1.1: Implementing the UNet</h3>
                    </section>

                    <section id="sectionb1.2" class="subsubsubsection">
                        <h3>1.2: Using the UNet to Train a Denoiser</h3>

                        <section id="sectionb1.2.1" class="subsubsubsection">
                            <h4>1.2.1: Using the UNet to Train a Denoiser</h4>
                        </section>

                        <section id="sectionb1.2.2" class="subsubsubsection">
                            <h4>1.2.2: Out-of-Distribution Testing</h4>
                        </section>
                    </section>
                </section>

                <section id="sectionb2" class="subsubsection">
                    <h2>Part 2: Training a Diffusion Model</h2>
                    
                    <section id="sectionb2.1" class="subsubsubsection">
                        <h3>2.1: Time Conditional UNet (TCUNet)</h3>
                    </section>

                    <section id="sectionb2.2" class="subsubsubsection">
                        <h3>2.2: Training TCUnet</h3>
                    </section>

                    <section id="sectionb2.3" class="subsubsubsection">
                        <h3>2.3: Sampling from TCUNet</h3>
                    </section>

                    <section id="sectionb2.4" class="subsubsubsection">
                        <h3>2.4: Class Conditional UNet (CCUNet) + Training CCUNet</h3>
                    </section>

                    <section id="sectionb2.5" class="subsubsubsection">
                        <h3>2.5: Sampling from TCUNet</h3>
                    </section>

                </section>
                
            </section>
            
        </main>
    </div>
</body>
</html>
